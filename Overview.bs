<pre class='metadata'>
Title: Incremental Font Transfer
Shortname: IFT
Status: WD
Prepare for TR: yes
Date: 2022-06-28
Group: webfontswg
Level: none
Markup Shorthands: css no
TR: https://www.w3.org/TR/IFT/
ED: https://w3c.github.io/IFT/Overview.html
Editor: Chris Lilley, W3C, https://svgees.us/, w3cid 1438
Editor: Myles C. Maxfield, Apple Inc., mmaxfield@apple.com, w3cid 77180
Editor: Garret Rieger, Google Inc., grieger@google.com, w3cid 73905
Abstract: This specification defines two methods to incrementally transfer fonts from server to client.
          Incremental transfer allows clients to load only the portions of the font they actually need
          which speeds up font loads and reduces data transfer needed to load the fonts. A font can
          be loaded over multiple requests where each request incrementally adds additional data.
</pre>

<!--
    for things that are not in specref
    https://www.specref.org/
-->

<pre class=link-defaults>
spec:fetch; type:dfn; for:/; text:status
spec:fetch; type:dfn; for:/; text:response
</pre>

<pre class=biblio>
{
  "PFE-report": {
    "href": "https://www.w3.org/TR/PFE-evaluation/",
    "authors": ["Chris Lilley"],
    "status": "Note",
    "publisher": "W3C",
    "title": "Progressive Font Enrichment: Evaluation Report",
    "date": "15 October 2020"
  },

  "Shared-Brotli": {
    "href": "https://datatracker.ietf.org/doc/html/draft-vandevenne-shared-brotli-format-09#section-3.2",
    "authors": [
      "J. Alakuijala",
      "T. Duong",
      "R. Obryk",
      "Z. Szabadka",
      "L. Vandevenne"
    ],
    "status": "Internet Draft",
    "title": "Shared Brotli Compressed Data Format",
    "date": "27 Jul 2021"
  },


  "OpenType-Variations": {
    "href": "https://docs.microsoft.com/en-us/typography/opentype/spec/otvaroverview",
    "authors": [],
    "status": "Note",
    "publisher": "Microsoft",
    "title": "OpenType Font Variations Overview",
    "date": "23 October 2020"
  },

  "fast-hash": {
    "href": "https://github.com/ztanml/fast-hash",
    "authors": ["ztanml"],
    "status": "Note",
    "publisher": "ztanml",
    "title": "fast-hash",
    "date": "22 October 2018"
  },

  "fetch": {
    "href": "https://fetch.spec.whatwg.org/",
    "authors": [],
    "status": "Living Standard",
    "publisher": "What WG",
    "title": "Fetch Standard",
    "date": "13 December 2021"
  }
}
</pre>

<style>
.conform:hover {background: #31668f}
.conform:target {padding: 2px; border: 2px solid #AAA; background: #31668f }
</style>

Introduction {#intro}
=====================

<em>This section is not normative.</em>

Incremental Font Transfer (IFT) is a collection of technologies to improve the latency of remote fonts
(or "web fonts") on the web. Without this technology, a browser needs to download every last byte of a
font before it can render any characters using that font. IFT allows the browser to download only some
of the bytes in the file, thereby decreasing the perceived latency between the time when a browser
realizes it needs a font and when the necessary text can be rendered with that font.

The success of WebFonts is unevenly distributed. This specification allows WebFonts to be used where
slow networks, very large fonts, or complex subsetting requirements currently preclude their use. For
example, even using WOFF 2 [[WOFF2]], fonts for CJK languages are too large to be practical.

There are two different methods which can be used to incrementally transfer fonts.

Patch Subset (IFTP) {#patch-subset}
----------------------------

In the the first method, <a href="#patch-subset">Patch Subset</a> is a protocol in which a server
generates binary patches which a client applies to a subset of the font in order to extend the coverage
of that subset. The server is stateless, it does not maintain any session data for clients between
requests.  Thus when a client requests the generation of a patch from the server it has to fully
describe the current subset of the font that it has in a way which allows the server to recreate it.

Generic binary patch algorithms are used which do not need to be aware of the specifics of the font
format. Typically a server will produce a patch by generating two [=font subset|font subsets=]: one
which matches what the client currently has and one which matches the extended subset the client
desires. A binary patch is then produced between the two subsets.

Binned (IFTB) {#binned}
------------------------------

The second method, <a href="#binned-incxfer">Binned</a>, is a font format which imposes no server-side
requirements (other than the server should be able to respond to byte-based range requests, if that
option is chosen). In this format each glyph is assigned by ID to one or more "bins", each of which
has a corresponding "chunk" file containing the outline data for those glyphs. Glyphs in bin 0 are
always included in the initially loaded file, which also contains all other OpenType tables for the
font.

The browser starts the transfer process by loading the initial file. It then uses an added IFTB table,
together with the OpenType cmap table, to determine which additional chunks, if any, are needed to
render the current content. It then requests those chunks from the server, unpacks them, integrates the
glyph data into the specified glyf, loca, CFF, CFF2, or gvar tables, and updates the IFTB table to
record which chunks have been integrated. As the page content is updated the chunk identification and
loading process repeats.

When desired, the initial file can be "pre-loaded" with chunks for a particular purpose, such as more
efficient support of target script.

Technical Motivation: Evaluation Report {#evaluation-report}
------------------------------------------------------------

(XXX: Evaluation report does not apply to IFTB and may need updating.) See the Progressive Font
Enrichment: Evaluation Report [[PFE-report]] for the investigation which led to this specification.

The evaluation report found that patch subset was generally more efficient in terms of overall
performance and transferred bytes than range request. However, Range Request is simpler to deploy for
many uses cases while still providing material improvments to loading performance for large fonts.

Performance Considerations and the use of Incremental Font Transfer {#performance-considerations}
--------------------------------------------------------

Using incremental transfer may not always be beneficial, depending on the characteristics of the font
and the content being rendered. This section provides non-normative guidance to help decide:

1. When incremental transfer should be utilized.
2. When used, which of the two methods should be utilized.

Incrementally loading a font has a fundemental performance tradeoff versus loading the whole font.
Simplistically, under incremental transfer less bytes may be transferred at the potential cost of
increasing the total number of network requests being made, and/or increased request processing
latency. In general incremental font transfer will be beneficial where the reduction in latency from
sending less bytes outweighs additional latency introduced by the incremental transfer method.

The first factor to consider is the language of the content being rendered. The evaluation report
contains the results of simulating incremental font transfer across three categories of languages
([[PFE-report#langtype]]). See it's conclusions [[PFE-report#conclusions]] for a discussion of the
anticipated performance of incremental font transfer across the language categories.

Next, how much of the font is expected to be needed? If it's expected that most of the font will be
needed to render the content then incremental font transfer is unlikely to be beneficial. In many cases
however only part of a font is expected to be needed. For example:

* If the font contains support for several languages but a user is expected to only render content
    in a subset of those languages.
       
* If the content being rendered uses a small subset of the total characters in a font. This is
    often the case for Chinese, Japanese, Korean, Emoji, and Icon fonts.

* Only a small amount of text is being rendered. For example a font that is only used for a
    headline.

(XXX: IFTB may be a better choice than static subsets in almost every practical case. Re-evaluate this
note.) An alternative to incremental transfer is to break a font into distinct subsets (typically by
script) and use the unicode range feature of @font-face to load only the subsets needed. However, this
can break rendering [[PFE-report#fail-subset]] if there are layout rules between characters in
different subsets. Incremental font transfer does not suffer from this issue as it maintains the
original font and all it's layout rules.

### Reducing the Number of Network Requests ### {#reduce-requests}

As discussed in the previous section the most basic implementation of incremental font transfer will
tend to increase the total number of requests made vs traditional font loading. Since each request will
require at least one round trip time, performance can be negatively impacted if too many requests are
made. Patch subset allows for more codepoints then needed to be requested, and in practice IFTB will
load many more glyphs than are strictly needed.  Intelligent use of this feature by an implementation
can help reduce the total number of requests being made. (XXX update:) The evaluation report explored
this by testing the performance of a basic character frequency based [[PFE-report#codepredict|codepoint
prediction]] scheme and found it improved overall performance.

Performant implementations should incorporate a similar mechanism which can select codepoints which are
likely to be needed in the future and preemptively load them. This will improve performance by reducing
the need to make additional requests for missing codepoints. The set of codepoints the client has and
the set they are requesting can be used in conjuction with codepoint occurence frequency and codepoint
usage in languages/scripts to make predictions on which additional codepoints are likely to be needed.

With IFTB the prediction mechanism will need to be part of the font format conversion, assigning glyphs
to bins according to language/script and frequency. In patch subset either the client and/or server
implementation can include a prediction mechanism. A side benefit to a client side prediction mechanism
is providing some obfuscation of the specific codepoints required by the client. This is further
discussed in [[#content-inference-from-character-set]].

### Deciding between Patch Subset and IFTB ### {#patchsubset-vs-iftb}

(XXX This whole section needs updating. Patch-subset is likely to return fewer codepoints, although
with prediction that becomes less true. IFTB requires no server-side compression and static arrangement
of bins makes it more compatible with caching, including regional caching. ("More compatible" in the
sense that chunk files will see a higher cache hit rate compared with subset and patch files.) All IFTB
data is compressed at Brotli level 11 upfront. And IFTB does not necessarily require an extra "round
trip", in that chunks can be requested as soon as the IFTB and CMAP tables arrive at the client, which
will be early in the data stream (when following recommended practice). It remains true that IFTB
transfers all other tables up-front while patch-subset will transfer parts of some of those tables.
Also: IFTB does not support variable axis subsetting (unless it is statically chosen) while Patch
Subset may support that.)

From a purely performance perspective patch subset is more performant than range request. There are
three main factors for this:

1. Range request requires an extra round trip on the very first load of a font to fetch the non-outline
    font data.

2. Patch subset is able to incrementally transfer all tables in the font, while range request is
    limited to only incrementally transferring glyph outline tables. In many fonts the majority of
    data is in the glyph outlines, however there are fonts that have significant amounts of data in
    the non outline tables.

3. Patch subset is able to compress incremental font data against previously loaded data from that
    font. This leads to better compression overall compared to range request.

See the evaluation report for a quantative assessment of the difference in performance of patch
subset versus range request [[PFE-report#analysis]].

The downside of using patch subset is that it requires server side processing to produce the patches,
while range request can work on any standard HTTP server that supports range requests:

*  This means that range request can be deployed easier, and in places such as CDN's where the content
    owner may not have control over the serving stack.
    
*  The server side processing required by patch subset will lead to increased processing costs (eg.
    CPU, RAM usage) per request vs range request.

Opt-In Mechanism {#opt-in}
==========================

(XXX Because IFTP is a protocol and IFTB is a format, I suspect most of this section and the related
technology questions are superfluous. However, we may want to have a related switch to choose between
IFTB chunk files and IFTB range-requests on the range file when both options are available.)

<em>This section is general to both IFT methods.</em>

Webpage's can choose to opt-in to either patch subset or range request incremental transfer for a font
via the use of a CSS font tech keyword ([[css-fonts-4#font-tech-definitions]]) inside the
''@font-face'' block.

There are three tech keywords available:

*  <code>incremental-patch</code>: Load the font incrementally using the patch subset method.
*  <code>incremental-range</code>: Load the font incrementally using the range request method.
*  <code>incremental-auto</code>:  Load the font incrementally. The particular method to use is
    determined by <a href="#method-negotiation">Method Negotiation</a>.

<div class=example>
The use of the <code>incremental-patch</code> keyword in this CSS rule indicates to the browser they
should use the patch subset IFT method to load the font.
<pre>
@font-face {
    font-family: "MyCoolWebFont";
    src: url("MyCoolWebFont.otf") tech(incremental-patch);
}
</pre>
</div>

Note: Each individual <code>@font-face</code> block may or may not opt-in to IFT. This is due to the
variety of ways fonts are used on web pages. Authors have control over which fonts they want to use
this technology with, and which they do not.

Note: the use of <code>incremental-auto</code> may incur a CORS preflight request for the initial
request of method negotiation, as the initial request sets a custom header.

Note: the IFT tech keywords can be used in conjuction with other font tech specifiers to perform
font feature selection. For example a <code>@font-face</code> could include two urls one with
<code>tech(incremental-patch, color-COLRv1)</code> and the other with
<code>tech(incremental-patch, color-COLRv0)</code>. The client would initiate an incremental patch
subset transfer to one of the URLs depending on which version of COLR is supported.


IFT Method Selection {#method-selection}
========================================

(XXX This section is also superfluous.)

<em>This section is general to both IFT methods.</em>

The client should have support for both patch subset and range request IFT. The client selects the
IFT method to utilize for a font load using the following procedure:

*  If the content has specified which method to use, such as via the <code>incremental-patch</code> or
    <code>incremental-range</code> font tech keyword (see: <a href="#opt-in">opt-in mechanism</a>),
    then that method should be used if the client supports it. If the specified method is not supported
    then the client should fallback to to loading the font non-incrementally.

*  Otherwise if the client does not know which particular IFT method(s) that the server hosting the
    font supports, such as when the <code>incremental-auto</code> font tech keyword is used, then
    <a href="#method-negotiation">method negotiation</a> should be used to determine the method.

The most recently specified method by the content takes precedence. For example if on a site the
first page specifies to use the patch subset method for a font URL, but the second page specifies
range request for the same font URL then the second page should load the font using range request.
Such cases will require the client to reset any previously stored state for that URL and start fresh
with the new method. In the case that <code>incremental-auto</code> is encountered where previously a
specific method was specified then the client can choose to continue using the previously selected
method.


IFT Method Negotiation {#method-negotiation}
--------------------------------------------

When the particular IFT method(s) that are supported by a server are not known, the client must
determine which method to use. Different clients may support different IFT methods, and different
servers may support different IFT methods, so a negotation occurs as such:

1.  The browser makes the first request to the server using the GET HTTP method ([[rfc9110#name-get]]).
     If the client prefers the <a href="#patch-incxfer">patch-subset method</a>, it sends the relevant
     [=patch request header=]. If the client prefers the range-request method, it does not send the
     header.

2.  If the server receives the patch request header and wishes to honor it, the server must reply
     according to [[#handling-patch-request]]. Otherwise, the server must reply with the
     [[RFC9110#range.requests]]
     <a href="https://www.rfc-editor.org/rfc/rfc9110.html#name-accept-ranges"><code>Accept-Ranges</code></a>
     header, if it supports HTTP Range Requests.
     
3.  If the client receives a font with a
     <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/otff#table-directory">table</a>
     identified by the 4-byte tag "IFTP", it commences using the patch-subset method.
     Otherwise, if the client receives the <code>Accept-Ranges: bytes</code> header, it commences
     using the range-request method. Otherwise, the whole font file is downloaded, and the current
     non-incremental loading behavior is used.

IFT Method Fallback {#fallback}
-------------------------------

<em>This section is not normative.</em>

This summarizes behaviors that result from the above method selection and negotiation sections.

If the content specifies the range request method:

<table class="data">
    <thead>
        <tr>
            <th>&nbsp;
            <th>Client supports range-request method
            <th>Client does not support range-request method
    <tbody>
        <tr>
            <th>Server supports range-request method
            <td>Range-request method is used.
            <td>Client falls back to non-incremental load of the full font file.
        <tr>
            <th>Server does not support range-request method.
            <td>Response is missing accept-ranges header. Client falls back to
                non-incremental load of the full font file.
            <td>Client falls back to non-incremental load of the full font file.
</table>

If the content specifies the patch subset method:

<table class="data">
    <thead>
        <tr>
            <th>&nbsp;
            <th>Client supports patch-subset method
            <th>Client does not support patch-subset method
    <tbody>
        <tr>
            <th>Server supports patch-subset method
            <td>Patch-subset method is used.
            <td>Client falls back to non-incremental load of the full font file.
        <tr>
            <th>Server does not support patch-subset method
            <td>Response is missing magic number. Client falls back to non-incremental load of the
            full font file.
            <td>Client falls back to non-incremental load of the
            full font file.
</table>

If the content does not specify a specific method:

<table class="data">
    <thead>
        <tr>
            <th>&nbsp;
            <th>Client prefers range-request method
            <th>Client prefers patch-subset method
    <tbody>
        <tr><th>Server supports both range-request method and patch-subset method
            <td>Client makes initial request without the patch request header, and possibly with the <code>Range</code> header. Because all patch-subset servers must support the range-request method, the server replies with <code>Accept-Ranges</code> and initial font data. Client/server commence using range-request method.

            <td>Client makes initial request with the patch request header. Server replies with the patch-subset magic number, and client/server commence using patch-subset method.
        <tr><th>Server supports only range-request method
            <td>Same as above.
            <td>Client makes initial request with the patch request header. Server replies with <code>Accept-Ranges</code> and initial font data. Client/server commence using range-request method.
        <tr><th>Server supports neither
            <td>Client makes initial request without the patch request header, and possibly with the <code>Range</code> header. Server replies without <code>Accept-Ranges</code> header, and sends the full font file to the client from beginning to end.
            <td>Client makes initial request to server with the patch request header. Server does not reply with the patch-subset magic number, and sends the full font file to the client from beginning to end.
</table>


Offline Usage {#offline-usage}
------------------------------

Special consideration must be taken when saving a page for offline usage that uses an incrementally
transferred font since the saved page won't be able to increment the font if content changes (eg.
due to javascript execution). In these cases, when using patch-subset the page saving mechanism should
download the full font by making a normal GET request without the [=patch request header=] to the font
url. When using IFTB the page saving mechanism should download and integrate all remaining chunks.

Preliminary Definitions {#prelim-definitions}
=============================================

Font Subset Description {#font-subset-des-def}
----------------------------------------------

A <dfn>font subset description</dfn> specifies the minimum data that a [=font subset=] must possess:

*  a set of codepoints,
*  a set of <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/featuretags">opentype
    layout features</a>,
*  and (in the case of a variable font) a <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/otvaroverview#terminology">design-variation space</a>.

Glyph Closure {#glyph-closure-def}
----------------------------------

The <dfn>glyph closure</dfn> of a font subset description is the full set of glyphs in the
font that may be needed to render any combination of the described codepoints and layout features.

Font Subset {#font-subset-def}
--------------------------

A <dfn>font subset</dfn> is a version of a font file modified relative to a font subset description
such that when the font subset is used to render any document or other text string consisting only of
codepoints, layout features and points in design space included in that description it must render
identically to the original font.  This includes rendering with the use of any optional typographic
features that a renderer may choose to use from the original font, such as hinting instructions.

By definition a font subset must contain the glyph closure of the font subset description, although
it can also contain other glyphs.  The IDs of the glyphs may be remapped, with other layout-related
tables in the font accordingly reduced to only support those glyphs. Alternatively, the IDs of the
glyphs may be retained and complete copies of those tables included in the font subset.


Patch Based Incremental Transfer {#patch-incxfer}
=================================================

Data Types {#data-types}
------------------------

This section lists all of the data types that are used to form the request and response messages
sent between the client and server.

### Encoding ### {#encoding}

All data types defined here are encoded into a byte representation for transport using CBOR
(Concise Binary Object Representation) [[!RFC8949]]. More information on how each data types
should be encoded by CBOR are given in the definition of those data types.

### Primitives ### {#primitives}

<table>
  <tr>
    <th>Data Type</th><th>Description</th><th>CBOR Major Type</th>
  </tr>
  <tr>
    <td><dfn>Integer</dfn></td><td>An integer value range [-2<sup>63</sup>, 2<sup>63</sup> - 1] inclusive.</td>
    <td>0 or 1</td>
  </tr>
  <tr>
    <td><dfn>Float</dfn></td><td>IEEE 754 Single-Precision Float.</td><td>7</td>
  </tr>
  <tr>
    <td><dfn>ByteString</dfn></td><td>Variable number of bytes.</td><td>2</td>
  </tr>
  <tr>
    <td><dfn>String</dfn></td><td>UTF-8 [[rfc3629]] text string.</td><td>3</td>
  </tr>
  <tr>
    <td><dfn>ArrayOf</dfn>&lt;Type&gt;</td><td>Array of a variable number of items of Type.</td><td>4</td>
  </tr>
</table>

### <dfn>SparseBitSet</dfn> ### {#sparsebitset-object}

A data structure which compactly stores a set of distinct unsigned integers. The set is represented as
a tree where each node has a fixed number of children that recursively sub-divides an interval into
equal partitions. A tree of height <i>H</i> with branching factor <i>B</i> can store set membership
for integers in the interval [0 to <i>B</i><sup><i>H</i></sup>-1] inclusive. The tree is encoded into
a [=ByteString=] for transport.

To construct the tree <i>T</i> which encodes set <i>S</i> first select the branching factor <i>B</i>
(how many children each node has). <i>B</i> can be 4, 8, 16, or 32.

Note: the encoder can use any of the possible branching factors, but it is recommended to use 4 as that
has <a href="https://github.com/w3c/PFE-analysis/blob/main/results/set_encoding_branch_factor.md">been
shown</a> to give the smallest encodings for most sets typically encountered.

Next, determine the height, <i>H</i>, of the tree:

<i>H</i> = ceil(log<sub><i>B</i></sub>(max(<i>S</i>) + 1))

If <i>S</i> is an empty set then <i>H</i> = 1.

Next create a tree of height H where all non-leaf nodes have <i>B</i> children. Each node in the tree
has a single value composed of <i>B</i> bits. Given a node <i>p</i> which has <i>B</i> children:
<i>c<sub>0</sub></i> ... <i>c<sub><i>B</i> - 1</sub></i> and is in a tree, <i>T</i>, of height
<i>H</i>, then:

*  D(<i>n</i>) is depth of node <i>n</i>: the number of edges between
    the root node and <i>n</i>.

*  Start(<i>c<sub>i</sub></i>) is the start (inclusive) of the interval  covered by
     <i>c<sub>i</sub></i> :<br/>
     Start(<i>c<sub>i</sub></i>) =
     Start(<i>p</i>) + <i>i</i> * <i>B</i><sup><i>H</i> - D(<i>c<sub>i</sub></i>)</sup>

*  End(<i>c<sub>i</sub></i>) is the end (exclusive) of the interval  covered by
     <i>c<sub>i</sub></i> :<br/>
     End(<i>c<sub>i</sub></i>) =
     Start(<i>p</i>) + (<i>i</i> + 1) * <i>B</i><sup><i>H</i> - D(<i>c<sub>i</sub></i>)</sup>

*  Start(root node) = 0

*  The value of node <i>p</i> is a string of <i>B</i> bits. If its bits are numbered from 0 (least
    significant) to <i>B</i> - 1 (most significant) then bit <i>i</i> will be 1 if the set <i>S</i>
    contains at least one member in the interval [Start(<i>c<sub>i</sub></i>),
    End(<i>c<sub>i</sub></i>)), otherwise bit <i>i</i> will be 0.

*  If for node <i>p</i>, End(<i>p</i>) - Start(<i>p</i>) = <i>B</i>, then <i>p</i> will have no
    children.

*  An empty set is considered to have no nodes.

The tree is encoded into a bit string. When appending multiple-bit values to the bit string, bits
are added in order from least significant bit to most significant bit.

First append 2 bits which encode the branching factor:

<table>
  <tr>
    <th>Bits&nbsp;</th><th>Branching Factor</th>
  </tr>
  <tr><td>00</td><td>2</td></tr>
  <tr><td>01</td><td>4</td></tr>
  <tr><td>10</td><td>8</td></tr>
  <tr><td>11</td><td>32</td></tr>
</table>

Then append the value <i>H</i> - 1 as a 5 bit unsigned integer. Next append a single 0 bit, which
is reserved for future use.

Next the nodes are encoded into the bit string by traversing the nodes of the <i>T</i> in level
order and appending the value for each non-zero node to the bit string. If all of the set values
covered by a node's interval are present within set <i>S</i>, then that node can instead be encoded
in the bit string as <i>B</i> bits all set to zero. All children of that node must not be encoded.

Lastly the bit string is converted into a ByteString by converting each consecutive group of 8 bits
into the next byte of the string.  If the number of bits in the bit string is not a multiple of 8, zero
bits are appended to the next multiple of 8.  The bit with the smallest index in the bit string is the
least significant bit in the byte and the bit with the largest index is the most significant bit.

<div class=example>
  The set {2, 33, 323} in a tree with a branching factor of 8 is encoded as the bit string:

  ```
  BitString:
  |- header |- lvl 0 |---- level 1 ----|------- level 2 -----------|
  |         |   n0   |   n1       n2   |   n3       n4       n5    |
  [ 01010000 10000100 10001000 10000000 00100000 01000000 00010000 ]

  Which then becomes the ByteString:
  [
    0b00001010,
    0b00100001,
    0b00010001,
    0b00000001,
    0b00000100,
    0b00000010,
    0b00001000
  ]
  ```

  First determine the height of the tree:

  <i>H</i> = ceil(log<sub>8</sub>(323 + 1)) = 3

  Then append

  *  branching factor = 8 = 10
  *  <i>H</i> - 1 = 2 = 00010
  *  reserved bit = 0

  Level 0:

  * root node, n<sub>0</sub> append 00100001. Bit 0 is set because there are set members in the interval
     [0, 64), and bit 5 is set due to members in the interval [320, 384).

  Level 1:

  * There will be two non-zero children corresponding to bit 0 and bit 5 in n<sub>0</sub>:
  * n<sub>1</sub> append 00010001. It is child 0 of n<sub>0</sub> and subdivides the interval
     [0, 64). Bit 0 is set since there are set members in [0, 8) and bit 4 for [32, 40).

  * n<sub>2</sub> append 00000001. It is child 5 of n<sub>0</sub> it subdivides the interval
     [320, 384). Bit 0 is set since there are set members in [320 - 328).

  Level 2:

  * n<sub>3</sub> append 00000100. Child 0 of n<sub>1</sub>, bit 2 is set for the interval [2, 3) or 2.
  * n<sub>4</sub> append 00000010. Child 4 of n<sub>1</sub>, bit 1 is set for the interval [33, 34) or 33.
  * n<sub>5</sub> append 00001000. Child 0 of n<sub>2</sub>, bit 3 is set for the interval [323, 324)
     or 323.

</div>

<div class=example>
  The set {} in a tree with a branching factor of 4 is encoded as the bit string:

  ```
  BitString:
  |- header- |
  |          |
  [ 00000000 ]

  Which then becomes the ByteString:
  [
    0b00000000,
  ]
  ```

  First determine the height of the tree. Because we are encoding an empty
  set height is:

  <i>H</i> = 1

  Then append

  *  branching factor = 2 = 00
  *  <i>H</i> - 1 = 0 = 00000
  *  reserved bit = 0

  Empty sets have no nodes, so no bytes beyond the header need to be appended.

</div>

<div class=example>
  The set {0, 1, 2, ..., 17} can be encoded with a branching factor of 4 as:

  ```
  BitString:
  |- header | l0 |- lvl 1 -| l2  |
  |         | n0 | n1 | n2 | n3  |
  [ 10010000 1100 0000 1000 1100 ]

  ByteString:
  [
    0b00001001,
    0b00000011,
    0b00110001
  ]
  ```

  First determine the height of the tree:

  <i>H</i> = ceil(log<sub>4</sub>(17 + 1)) = 3

  Then append

  *  branching factor = 4 = 01
  *  <i>H</i> - 1 = 2 = 00010
  *  reserved bit = 0

  Level 0:
  *  n<sub>0</sub> append 0011. Bit 0 set for [0, 16), bit 1 set for [16, 32)

  Level 1:
  *  n<sub>1</sub> append 0000. All bits zero to indicate interval [0, 16) is fully filled.
  *  n<sub>2</sub> append 0001. Bit 0 set for [16, 20)

  Level 2:
  *  n<sub>3</sub> append 0011. Bit 0 set for value 16, bit 1 set for value 17.

</div>

### <dfn>IntegerList</dfn> ### {#integerlist-object}

A data structure which compactly represents a list of non-negative integers
from 0 to 2<sup>31</sup>-1. The list is encoded into a [=ByteString=] for transport.

There are three steps of encoding/compression: first delta, second zig-zag, and finally UIntBase128.
The final [=ByteString=] result is simply the concatenation of the individual UIntBase128
encoded bytes.

[=IntegerList=] encoding must reject an input list which contains values not in the range
0 to 2<sup>31</sup>-1. Likewise if decoding an IntegerList results in values which are not
in the range 0 to 2<sup>31</sup>-1 the list is invalid and must be rejected.

#### Delta Encoding #### {#integerlist-deltas}

Delta encoding converts a list of integers to a list of deltas between them.

A list L of n integers L<sub>i<sub>0..n-1</sub></sub> is converted into a list
of N integers D<sub>i<sub>0..n-1</sub></sub> as follows:

* D<sub>0</sub> = L<sub>0</sub>
* D<sub>i = 1..n-1</sub> = L<sub>i</sub> - L<sub>i-1<sub>

This has the effect of reducing the magnitude of the values, which reduces the number
of bytes required in the UIntBase128 encoding, below.

<div class="example">
```
// Note: unsorted
int_list = [23, 43, 12, 3, 67, 68, 69, 0]
delta_list = [23, 20, -31, -9, 64, 1, 1, -69]
```
</div>

#### Zig-Zag Encoding #### {#integerlist-zigzag}

Zig-Zag encoding reversibly converts signed integers to unsigned integers,
using the same number of bits. The entire range of values is supported.
This step is required, as the [[#integerlist-uintbase128]] step works on
unsigned integers only. The encoding maps positive integer values to even positive integers and
negative integer values to odd positive integers. Psuedo code:

```
encode(n):
  if n >= 0:
    return n * 2
  else:
    return (n * -2) - 1

decode(n) {
  if n & 1:
    return -((n + 1) / 2)
  else:
    return n / 2
```

<div class="example">
<table>
<tr><th>Value</th><th>Zig-Zag Encoding</th></tr>
<tr><td>0</td><td>0</td></tr>
<tr><td>1</td><td>2</td></tr>
<tr><td>2</td><td>4</td></tr>
<tr><td>3</td><td>6</td></tr>
<tr><td>4</td><td>8</td></tr>
<tr><td>-1</td><td>1</td></tr>
<tr><td>-2</td><td>3</td></tr>
<tr><td>-3</td><td>5</td></tr>
<tr><td>-4</td><td>7</td></tr>
</table>
</div>

<div class="example">
```
delta_list = [23, 20, -31, -9, 64, 1, 1, -69]
zig_zag_encoded_list = [46, 40, 61, 17, 128, 2, 2, 137]
```
</div>

#### UIntBase128 Encoding #### {#integerlist-uintbase128}

UIntBase128 is a variable length encoding of unsigned integers,
suitable for values up to 2<sup>32</sup>-1. A UIntBase128 encoded number
is a sequence of bytes for which the most significant bit is set for all but
the last byte, and clear for the last byte. The number itself is base 128
encoded in the lower 7 bits of each byte. Thus, a decoding procedure for
a UIntBase128 is: start with value = 0. Consume a byte, setting value =
old value times 128 + (byte bitwise-and 127). Repeat last step until
the most significant bit of byte is false.

UIntBase128 encoding format allows a possibility of sub-optimal encoding, where e.g.
the same numerical value can be represented with variable number of bytes (utilizing
leading zeros). For example, the value 63 could be encoded as either one byte 0x3F
or two (or more) bytes: [0x80, 0x3f].
<span class="conform server client" id="conform-uintbase128-illegal">An encoder must not allow this
to happen and must produce shortest possible encoding. A decoder must reject the response/request
if it encounters a UIntBase128-encoded value with leading zeros (a value that starts with the byte
0x80), if UIntBase128-encoded sequence is longer than 5 bytes, or if a UIntBase128-encoded value
exceeds 2<sup>32</sup>-1.</span> Pseudo-code:

```
bool ReadUIntBase128( data, *result ) {
  UInt32 accum = 0;

  for (i = 0; i < 5; i++) {
    UInt8 data_byte = data.getNextUInt8();

    // No leading 0's
    if (i == 0 && data_byte == 0x80) return false;

    // If any of top 7 bits are set then << 7 would overflow
    if (accum & 0xFE000000) return false;

    accum = (accum << 7) | (data_byte & 0x7F);

    // Spin until most significant bit of data byte is false
    if ((data_byte & 0x80) == 0) {
      *result = accum;
      return true;
    }
  }
  // UIntBase128 sequence exceeds 5 bytes
  return false;
}
```

<div class="example">
```
Value       Output Bytes
0           00000000
1           00000001
2           00000010
3           00000011
127         01111111
128         10000001 00000000
255         10000001 01111111
16256       11111111 00000000
2080768     11111111 10000000 00000000
266338304   11111111 10000000 10000000 00000000
4294967295  10001111 11111111 11111111 11111111 01111111
```
</div>

<div class="example">
```
zig_zag_encoded_list = [46, 40, 61, 17, 128, 2, 2, 137]
bytes = [2E 28 3D 11 81 00 02 02 81 09]
         └┘ └┘ └┘ └┘ └───┘ └┘ └┘ └───┘
```
</div>


### <dfn>SortedIntegerList</dfn> ### {#sortedintegerlist-object}

A data structure which compactly represents a sorted list of ascending non-negative integers
(0 to 2<sup>32</sup>-1). The list is encoded into a [=ByteString=] for transport.

This is a variation on [=IntegerList=] with better compression. Sorted lists only use two steps of
encoding/compression: first deltas and then UIntBase128. The [[#integerlist-zigzag]] step is skipped.
This allows twice the range in UIntBase128, so that single bytes may be used more often.

[=SortedIntegerList=] encoding must reject an input list which contains values not in the range
0 to 2<sup>32</sup>-1.
<span class="conform server client" id="conform-sorted-integer-list-rejects-illegal">
Likewise if decoding an [=IntegerList=] results in values which are not
in the range 0 to 2<sup>32</sup>-1 the list is invalid and must be rejected.
</span>

### <dfn>RangeList</dfn> ### {#rangelist-object}

A RangeList encodes a set of non-negative integers (0 to 2<sup>32</sup>-1). The set is encoded as a
list of disjoint intervals. Each interval is represented by two integers, a
start (inclusive) and end (inclusive).

A RangeList is a list of n pairs
[min<sub>i<sub>0..n-1</sub></sub>, max<sub>i<sub>0..n-1</sub></sub>].
The list must be non-decreasing, i.e. min<sub>i=1..n-1</sub> >= max<sub>i-1<sub>.

To encode this list, we convert it to a list L of 2n integers, where
L<sub>2i</sub> = min<sub>i</sub> and L<sub>2i+1</sub> = max<sub>i</sub> for
i = 0..n-1.

L is a sorted list of integers, so a [=SortedIntegerList=] is used to encode it as a
[=ByteString=].

<div class="example">
```
range_list = [3, 10], [13, 268]
int_list = [3, 10, 13, 268]
delta_list = [3, 7, 3, 255]
bytes = [03 07 03 81 7F]
```
</div>

### <dfn>FeatureTagSet</dfn> ### {#featuretagset-object}

A FeatureTagSet encodes a set of zero or more <a
href="https://docs.microsoft.com/en-us/typography/opentype/spec/featuretags">opentype layout feature
tags</a>.  Each feature tag is mapped to an integer value and then the set of mapped integers are
encoded in a [=SortedIntegerList=]. Feature tags are mapped to integers as follows:

*  If the tag is found in [[#feature-tag-list]]:

    *  If the "Encoded As" column corresponding to the tag is "default" then the tag is skipped and
        not encoded.

    *  Else, the tag is mapped to the integer value in the "Encoded As" column.

*  Otherwise: the tag is converted to an integer by treating the tag's 4 byte string as a 4 byte
    little endian integer.

The final encoding is produced by sorting the mapped integers (exlcuding tags which are skipped)
into ascending order and then encoding the sorted list as a [=SortedIntegerList=].

When decoding a FeatureTagSet the integer values are mapped back to the original tags by reversing
the above mapping rules.
<span class="conform server client" id="conform-feature-tag-set-defaults">Additionally all
default features in [[#feature-tag-list]] must be added to the decoded set.</span>

### <dfn>AxisSpace</dfn> ### {#AxisSpace}

Stores a set of intervals on one or more open type variation axes [[opentype-variations]]</a>.
Encoded as a CBOR map (major type 5). The key in each pair is an
<a href="https://docs.microsoft.com/en-us/typography/opentype/spec/fvar#variationaxisrecord"> axis
tag</a>. It is encoded as a [=ByteString=] containing exactly 4 ASCII characters. The value in each
pair is an [=ArrayOf=]&lt;[=AxisInterval=]&gt;.  <span class="conform client server"
id="conform-axis-space-disjoint">The list of intervals for a each axis tag must be disjoint.</span>

### Objects ### {#objects}

Objects are data structures comprised of key and value pairs.
<span class="conform server client" id="conform-object">Objects are encoded via CBOR as maps (major
type 5)</span>. Each key and value pair is encoded as a single map entry. Keys are always unsigned
integers and are encoded using major type 0. Values are encoded using the encoding specified by the
type of the value.

All fields in an object are optional and do not need to have an associated value. Conversely when
decoding and object fields may be present which are not specified in the schema.
<span class="conform server client" id="conform-object-unrecognized-field">
The decoder must ignore without error any key and value pairs where the key is not recognized.
</span>

There are several types of object used, each type is defined by a schema in [[#schemas]]. The schema
for a type specifies for each field:

*  A human readable name for the field. For reference only, not used in the encoding.
*  A unsigned integer id for the field. This is used as the key in the encoding.
*  The type of the value stored in this field. Can be any of the types defined in [[#data-types]]
    including object types.

## Object Schemas ## {#schemas}

### <dfn>CompressedSet</dfn> ### {#CompressedSet}

Encodes a set of unsigned integers. The set is not ordered and does not
allow duplicates. Members of the set are encoded into either a [=SparseBitSet=] or a
[=RangeList=]. To obtain the final set the members of [=CompressedSet/sparse_bit_set=]
and the list of ranges in [=CompressedSet/range_deltas=] are unioned together.

<table>
  <tr><th>ID&nbsp;</th><th>Field Name</th><th>Type</th></tr>
  <tr>
    <td>0</td>
    <td><dfn for="CompressedSet">sparse_bit_set</dfn></td>
    <td>[=SparseBitSet=] ([=ByteString=])</td>
  </tr>
  <tr>
    <td>1</td>
    <td><dfn for="CompressedSet">range_deltas</dfn></td>
    <td>[=RangeList=] ([=ByteString=])</td>
  </tr>
</table>

### <dfn>AxisInterval</dfn> ### {#AxisInterval}

<table>
  <tr><th>ID</th><th>Field Name</th><th>Value Type</th></tr>
  <tr>
    <td>0</td>
    <td><dfn for="AxisInterval">start</dfn></td>
    <td>[=Float=]</td>
  </tr>
  <tr>
    <td>1</td>
    <td><dfn for="AxisInterval">end</dfn></td>
    <td>[=Float=]</td>
  </tr>
</table>

[=AxisInterval=] defines an interval (from [=AxisInterval/start=] to [=AxisInterval/end=] inclusive)
on some variable axis in a font.

For an [=AxisInterval=] object to be well formed:

*  <span class="conform client server" id="conform-axis-interval-start">
    [=AxisInterval/start=] must be set.
    </span>

*  <span class="conform client server" id="conform-axis-interval-end">
    [=AxisInterval/end=] is optional, if set it must be greater than [=AxisInterval/start=].</span>
    If [=AxisInterval/end=] is not set then this interval is a single point, [=AxisInterval/start=].

### <dfn>PatchRequest</dfn> ### {#PatchRequest}

<table>
  <tr><th>ID</th><th>Field Name</th><th>Value Type</th></tr>
  <tr>
    <td>0</td>
    <td><dfn for="PatchRequest">codepoints_have</dfn></td>
    <td>[=CompressedSet=]</td></tr>
  <tr>
    <td>1</td>
    <td><dfn for="PatchRequest">codepoints_needed</dfn></td>
    <td>[=CompressedSet=]</td></tr>
  <tr>
    <td>2</td>
    <td><dfn for="PatchRequest">indices_have</dfn></td>
    <td>[=CompressedSet=]</td></tr>
  <tr>
    <td>3</td>
    <td><dfn for="PatchRequest">indices_needed</dfn></td>
    <td>[=CompressedSet=]</td></tr>
  <tr>
    <td>4</td>
    <td><dfn for="PatchRequest">features_have</dfn></td>
    <td>[=FeatureTagSet=]</td></tr>
  <tr>
    <td>5</td>
    <td><dfn for="PatchRequest">features_needed</dfn></td>
    <td>[=FeatureTagSet=]</td></tr>
  <tr>
    <td>6</td>
    <td><dfn for="PatchRequest">axis_space_have</dfn></td>
    <td>[=AxisSpace=]</td></tr>
  <tr>
    <td>7</td>
    <td><dfn for="PatchRequest">axis_space_needed</dfn></td>
    <td>[=AxisSpace=]</td></tr>
  <tr>
    <td>8</td>
    <td><dfn for="PatchRequest">ordering_checksum</dfn></td>
    <td>[=Integer=]</td></tr>
  <tr>
    <td>9</td>
    <td><dfn for="PatchRequest">original_font_checksum</dfn></td>
    <td>[=Integer=]</td></tr>
  <tr>
    <td>10</td>
    <td><dfn for="PatchRequest">base_checksum</dfn></td>
    <td>[=Integer=]</td></tr>
  <tr>
    <td>11</td>
    <td><dfn for="PatchRequest">fragment_id</dfn>
    </td><td>[=String=]</td></tr>
  <tr>
    <td>12</td>
    <td><dfn for="PatchRequest">codepoint_ordering</dfn></td><td>[=IntegerList=]</td></tr>
</table>

For a [=PatchRequest=] object to be well formed:

*  <span class="conform client server" id="conform-request-ordering-checksum">
    If either of [=PatchRequest/indices_have=] or [=PatchRequest/indices_needed=] is set to a non-empty
    set then [=PatchRequest/ordering_checksum=] must be set.</span>
*  <span class="conform client server" id="conform-request-base-checksum">
    If [=PatchRequest/codepoints_have=] or [=PatchRequest/indices_have=] is set to a non-empty set then
    [=PatchRequest/original_font_checksum=] and [=PatchRequest/base_checksum=] must be set.</span>

### <dfn>ClientState</dfn> ### {#ClientState}

<table>
  <tr><th>ID</th><th>Field Name</th><th>Value Type</th></tr>

  <tr>
    <td>0</td>
    <td><dfn for="ClientState">original_font_checksum</dfn></td><td>[=Integer=]</td></tr>

  <tr>
    <td>1</td>
    <td><dfn for="ClientState">codepoint_ordering</dfn></td><td>[=IntegerList=]</td></tr>

  <tr>
    <td>2</td>
    <td><dfn for="ClientState">subset_axis_space</dfn></td><td>[=AxisSpace=]</td></tr>

  <tr>
    <td>3</td>
    <td><dfn for="ClientState">original_axis_space</dfn></td><td>[=AxisSpace=]</td></tr>

  <tr>
    <td>4</td>
    <td><dfn for="ClientState">original_features</dfn></td><td>[=FeatureTagSet=]</td></tr>

</table>

Client {#client}
----------------

<h4 algorithm id="extend-subset">Extending the Font Subset</h4>

This algorithm is used by the client to extends its [=font subset=] to cover additional codepoints,
features, and/or design-variation space.

<dfn abstract-op>Extend the font subset</dfn>

The inputs to this algorithm are:

* <var>font URL</var>: a URL where the font to be extended is located.

* <var>fragment identifier</var> (optional): if the font at the font url is a font collection,
    the fragment identifier ([[rfc8081#section-4.2]]) identifies a single font within the collection.

* <var>font subset</var> (optional): previously loaded [=font subset=] for the given
    font url, or null.

* <var>desired subset description</var>: a [=font subset description|description=] of the desired
    minimum [=font subset=].

* <var>fetch algorithm</var>: algorithm for fetching HTTP resources, such as [[fetch]]. The remainder
    of this section is desribed in terms of [[fetch#fetching]], but it is allowed to substitute
    whatever HTTP fetching algorithm the user agent supports.

The algorithm outputs:

* Extended Font Subset: [=font subset=] that has been updated to cover at least the requested subset
    definition.

* Cache fields: HTTP cache fields [[rfc9111#name-field-definitions]] describing how client state
    can be cached, or null.

The algorithm:

1. Compare the <var>desired subset description</var> to the <var>font subset</var>. If the
     <var>font subset</var> is a superset of <var>desired subset description</var> then return
     <var>font subset</var>, and null for the cache fields.

2. If <var>font subset</var> is set then load the <var>client state</var> from the
    <var>font subset</var>. Client state is stored in the <var>font subset</var> as a
    <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/otff#table-directory">table</a>
    identified by the 4-byte tag 'IFTP'. The contents of the table are a single [=ClientState=] object
    encoded via CBOR.

     * If <var>font subset</var> does not have an "IFTP" table, then this is not an incrementally
         loaded font and cannot be extended any further. Return <var>font subset</var>.

3. Otherwise make an HTTP request using the <var>fetch algorithm</var>:

     * The request [=request/method=] must be either "GET" or "POST".

     * The request [=request/destination=] must be "font".

     * The request CORS [=request/mode=] must be "cors".

     * The request [=request/cache mode=] should be "no-store".

     * The request URL [=url/scheme=] must be "https".

     * The request URL [=url/path=] is set to the input <var>font URL</var>.

     * The request must include an [[rfc9110#name-accept-encoding|Accept-Encoding]] header which lists
         at minimum one of the encodings from [[#patch-encodings]].

     * If [=request/method=] is "POST" then, request [=request/body=] must be a single
         [=PatchRequest=] object encoded via CBOR.

     * Otherwise if [=request/method=] is "GET" then, a [=header=] with name
         <code>Font-Patch-Request</code> (the <dfn export>patch request header</dfn>)
         and whose value is a single
          [=PatchRequest=] object encoded via CBOR and then
          base64url encoding [[rfc4648]] must be added to the request's header list.

     Any request and/or url parameters which are not specified here should be set based on
     the user agent's normal handling for font requests. For example if this font load is
     from a CSS font face, then [[css-fonts-4#font-fetching-requirements]] should be followed.

     The fields of the [=PatchRequest=] object should be set
     as follows:

     *  [=PatchRequest/codepoints_have=]: set to exactly the set of codepoints that the current
         <var>font subset</var> contains data for. If the current
         <var>font subset</var> is not set then this field is left unset. If
         <var>client state</var> is available and has a [=ClientState/codepoint_ordering=] then
         this field should not be set.

     *  [=PatchRequest/codepoints_needed=]: set to the set of codepoints that the client wants to
         add to its [=font subset=]. That is the codepoint set from <var>desired subset
         definition</var> minus the codepoints already in the <var>font subset</var>. If
         <var>client state</var> is available and has a [=ClientState/codepoint_ordering=] then
         this field should not be set.

     *  [=PatchRequest/indices_have=]: encodes the set of additional codepoints that the current
         <var>font subset</var> contains data for. The codepoint values are transformed
         to indices by applying the [[#codepoint-reordering]] specified by
         [=ClientState/codepoint_ordering=] to each codepoint value. If
         the <var>client state</var> is not available or it does not have a
         [=ClientState/codepoint_ordering=] then this field should not be set.

     *  [=PatchRequest/indices_needed=]: encodes the set of codepoints that the client wants to add to
         its [=font subset=]. That is the codepoint set from <var>desired subset
         definition</var> minus the codepoints already in <var>font subset</var>.
         The codepoint values are transformed to indices by applying the [[#codepoint-reordering]]
         specified by [=ClientState/codepoint_ordering=] to each codepoint value. If
         the <var>client state</var> is not available or it does not have a
         [=ClientState/codepoint_ordering=] then this field should not be set.

     *  [=PatchRequest/features_have=]: set to the list of
         <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/featuretags">
         opentype layout feature tags</a> that the current <var>font subset</var> has data
         for. If the current <var>font subset</var> is not set then this
         field is left unset. Additionally, if the current <var>font subset</var> has all
         data for features present in the [=original font=] then this field can be unset.

     *  [=PatchRequest/features_needed=]: set to the list of feature tags that the client wants to add
         to the current <var>font subset</var>. That is the feature set from <var>desired subset
         definition</var> minus the set of features already in <var>font subset</var>.
         If the client wishes to add all remaining layout features from the [=original font=] to it's
         subset then this field should be unset.

     *  [=PatchRequest/axis_space_have=]: set to the current value of
         [=ClientState/subset_axis_space=] saved in the <var>client state</var> for this font. If
         <var>client state</var> is not available then this field is unset.

     *  [=PatchRequest/axis_space_needed=]: set to the intervals of each variable axis in the
         [=original font=] that the client wants to add to its <var>font subset</var> as defined in the
         <var>desired subset description</var>. If the client wants an
         entire axis from the [=original font=] then that axis should not be listed.

     *  [=PatchRequest/ordering_checksum=]: If either of [=PatchRequest/indices_have=] or
         [=PatchRequest/indices_needed=] is set then this must be set to the checksum of the
         [=ClientState/codepoint_ordering=] saved in the <var>client state</var>. The checksum
         is computed via [[#reordering-checksum]].

     *  [=PatchRequest/original_font_checksum=]:
         Set to saved value for [=ClientState/original_font_checksum=] in the <var>client state</var>
         for this font. If there is no <var>client state</var> leave this field unset.

     *  [=PatchRequest/base_checksum=]:
         Set to the checksum of the <var>font subset</var>. See: [[#computing-checksums]].

     *  [=PatchRequest/fragment_id=]:
         If a <var>fragment identifier</var> was provided as an input then this field must be set to
         the provided <var>fragment identifier</var>, otherwise it must be left unset.


     Note: It is allowed for the client to request more codepoints then it strictly needs. For
     example, on slower connections it may be more performant to request extra codepoints if
     that is likely to prevent a future request from needing to be sent.

4. Invoke [$Handle server response$] with the response from the server and the <var>font subset</var>
    then return the result.

Note: POST is preferred for the HTTP method since it will not cause a CORS preflight request
and the request object is more compactly encoded. GET should only be used during
<a href="#method-negotiation">method negotiation</a>.

<h4 algorithm id="handling-patch-response">Handling Server Response</h4>

If a server is able to succsessfully process a [=PatchRequest=]
it will respond with HTTP [=response/status=] code 200 and the [=response/body=] of the response will
be an encoded representation of the extended font subset. The encoded representation may be a binary
patch against the current font subset.

<dfn abstract-op>Handle server response</dfn>

Inputs:

* <var>server response</var>: HTTP [=response=] to a patch request.

* <var>font subset</var> (optional): existing [=font subset=] which is  being extended. May be null.

The algorithm outputs:

* Extended Font Subset: [=font subset=] that has been updated to cover at least the requested subset
    definition.

* Cache fields: HTTP cache fields [[rfc9111#name-field-definitions]] describing how client state
    can be cached, or null.

The algorithm:

1.  If the <var>server response</var> has [=response/status=] other than 200:

     *  If it is a redirect [=status=]: follow normal redirect handling, such as
         [[fetch#http-redirect-fetch]] and then go back to step 1.

     *  If [=response/status=] is 412, then the server does not recognize the codepoint ordering
         used by the client. The client should resend the request that triggered this response but also
         set the [=PatchRequest/codepoint_ordering=] field on the request to the
         [=ClientState/codepoint_ordering=] in the client state table within <var>font subset</var>.

     *  All other statuses, the [=font subset=] extension has failed. Invoke
         [$Handle failed font load$] and return the result.

2.  Decode the <var>server response</var> [=response/body=] by applying the appropriate decoding as
     specified by the [[rfc9110#name-content-encoding|Content-Encoding]] header. If the
     [[rfc9110#name-content-encoding|Content-Encoding]] is one of those from [[#patch-encodings]] then
     the input <var>font subset</var> will be used as the source file for the decoding operation. The
     decoded response is the new extended font subset. Return the extended font subset and any cache
     headers that were set on the <var>server response</var>.

<dfn abstract-op>Handle failed font load</dfn>

If the font load or extension has failed the client should choose one of the following options:

1.  If the client has a saved [=font subset=], it may choose to use that and then use the user
      agent's existing font fallback mechanism for codepoints not covered by the subset.

2.  The client may re-issue the request as a regular non incremental font fetch to the same
      [=url/path=]. It must not include the patch subset request parameter or header. This will load
      the entire [=original font=].

3.  Discard the saved [=font subset=], and use the user agent's existing font fallback mechanism.

<h4 algorithm id="load-a-font">Load a Font in a User Agent with a HTTP Cache</h4>

The previous section [[#extend-subset]] provides no guidance on how a user agent should handle
saving the font subset and client state between invocations of the subset extension algorithm. This
section provides an algorithm that user agents which implement [[fetch]] should use to save the font
subset to the user agent's HTTP cache ([[RFC9111]]).

<dfn abstract-op>Load a font with a HTTP Cache</h4>

The inputs to this algorithm:

* <var>font URL</var>: a URL where the font to be extended is located.

* <var>fragment identifier</var> (optional): if the font at the font url is a font collection,
    the fragment identifier ([[rfc8081#section-4.2]]) identifies a single font within the collection.

* <var>desired subset description</var>: a [=font subset description|description=] of the desired
    minimum [=font subset=].

* <var>fetch algorithm</var>: algorithm for fetching HTTP resources, such as [[fetch]]. The remainder
    of this section is desribed in terms of [[fetch#fetching]], but it is allowed to substitute
    whatever HTTP fetching algorithm the user agent supports.

The algorithm outputs:

*  A [=font subset=] which covers at minimum the input subset description.

The algorithm:

1.  Make a HTTP fetch:

     * The request [=request/method=] is "GET".

     * The request [=request/destination=] must be "font".

     * The request CORS [=request/mode=] must be "cors".

     * The request URL [=url/scheme=] must be "https".

     * The request URL [=url/path=] is set to the input font URL.

     * The request [=request/cache mode=] is "only-if-cached".

2.  If the request is successful and the response is "fresh" ([[RFC9111#name-freshness]])
     then invoke [$Extend the font subset$] with:

     *  Font url set to the input <var>font URL</var>.

     *  Fragment identifier set to the input <var>fragment identifier</var>

     *  Font subset set to the response.

     *  Desired subset description set to the input <var>desired subset description</var>.

     *  Fetch algorithm set to the input <var>fetch algorithm</var>.

     Once that returns go to step 4.

3.  Otherwise, invoke [$Extend the font subset$] with:

     *  Font url set to the input <var>font URL</var>.

     *  Fragment identifier set to the input <var>fragment identifier</var>

     *  Font subset set to null.

     *  Desired subset description set to the input <var>desired subset description</var>.

     *  Fetch algorithm set to the input <var>fetch algorithm</var>.

     Once that returns go to step 4.

4.  If the returned cache fields are non-null update the cache entry for the input
     font url with the returned client state and returned cache fields.

5.  Return the returned [=font subset=].


Server: Responding to a PatchRequest {#handling-patch-request}
--------------------------------------------------------------

<span class="conform server" id="conform-successful-response">If the server receives a well formed
[=PatchRequest=] over HTTPS for a font the server has and that was
populated according to the requirements in [[#extend-subset]] then it must respond with HTTP
[=response/status=] code 200.</span>

The [=url/path=] in the request [=request/url=] identifies the specific font that a patch is desired
for. If the request has the [=PatchRequest/fragment_id=] field set and the file identified by
[=url/path=] is a font collection, then [=PatchRequest/fragment_id=] identifies the font within
that collection that a patch is desired for. The identified font is referred to as the
<dfn>original font</dfn> in the rest of this section.

From the request object the server can produce two codepoint sets:

1.  Codepoints the client has: formed by the union of the codepoint sets specified by
     [=PatchRequest/codepoints_have=] and [=PatchRequest/indices_have=].
     <span class="conform server" id="conform-remap-codepoints-have">The indices in
     [=PatchRequest/indices_have=] must be mapped to codepoints by the application of the
     codepoint reordering with a checksum matching [=PatchRequest/ordering_checksum=].</span>

2.  Codepoints the client needs: formed by the union of the codepoint sets specified by
     [=PatchRequest/codepoints_needed=] and [=PatchRequest/indices_needed=].
     <span class="conform server" id="conform-remap-codepoints-needed">The indices in
     [=PatchRequest/indices_needed=] must be mapped to codepoints by the application of the
     codepoint reordering with a checksum matching [=PatchRequest/ordering_checksum=].</span>

Note: the request may optionally set [=PatchRequest/codepoint_ordering=] which is used by the client to
provide the exact codepoint ordering that was used to encode [=PatchRequest/indices_have=] and
[=PatchRequest/indices_needed=].

Likewise, the server can produce two sets of
<a href="https://docs.microsoft.com/en-us/typography/opentype/spec/featuretags">opentype layout
feature tags</a>:

1.  Feature tags the client's subset has: specified by [=PatchRequest/features_have=]. If the field is
     unset this indicates the client's subset contains all features in the [=original font=].

2.  Feature tags the client needs: specified by [=PatchRequest/features_needed=]. If the field is unset
     this indicates the client wants all features in the [=original font=].

Lastly, the server can produce two variable axis spaces:

1.  Axis space the client has: specified by [=PatchRequest/axis_space_have=]. If any axes in the font
     are not specified in [=PatchRequest/axis_space_have=] then for those axes add their entire
     interval from the [=original font=].

2. Axis space the client needs: specified by [=PatchRequest/axis_space_needed=]. If any axes in the
     font are not specified in [=PatchRequest/axis_space_needed=] then for those axes add their entire
     interval from the [=original font=].

<span class="conform server" id="conform-bad-reordering">
If the server does not recognize the codepoint ordering used by the client, it must respond
with [=response/status=] code 412. This will instruct the client to resend the request including
the codepoint ordering it has.
</span>

<span class="conform server" id="conform-response-valid-patch">
Otherwise when the response is decoded by the client following the process in
[[#handling-patch-response]] to a [=font subset=] with checksum [=PatchRequest/base_checksum=] it must
result in an extended [=font subset=]:
</span>

*  <span class="conform server" id="conform-response-subset">That contains data for at least the union
    of the set of codepoints needed and the sets of codepoints the client already has.</span>

*  <span class="conform server" id="conform-response-subset-features">That contains data for at least
    the union of the set of features needed and the sets of features the client already has.</span>

*  <span class="conform server" id="conform-response-subset-axis-space">That contains a variation axis
    space that covers at least the union of the axis space the client has and the axis space the
    client needs.</span>


*  <span class="conform server" id="conform-response-client-state">That has a
    <a href="https://learn.microsoft.com/en-us/typography/opentype/spec/otff#table-directory">table</a>
    which is identified by the tag 'IFTP' whose content is a single [=ClientState=] object encoded via
    CBOR:</span>

    *  <span class="conform server" id="conform-response-client-state-original-checksum">The
        [=ClientState/original_font_checksum=] field must be set to the checksum of the
        [=original font=] computed by the procedure in [[#computing-checksums]].</span>

    *  <span class="conform server" id="conform-response-client-state-codepoint-ordering">
         The [=ClientState/codepoint_ordering=] field must be set following
         [[#codepoint-reordering]].</span>

    *  <span class="conform server" id="conform-response-client-state-subset-axis-space-field">
         If the [=original font=] has variation axes, the
         [=ClientState/subset_axis_space=] field must be set to the axis space covered by the
         [=font subset=].</span>

    *  <span class="conform server" id="conform-response-client-state-original-axis-space">
         If the [=original font=] has variation axes, the
         [=ClientState/original_axis_space=] field must be set to the axis space covered by
         the [=original font=].</span>

    *  <span class="conform server" id="conform-response-client-state-original-features">
        The [=ClientState/original_features=] field must be set to the list of
        <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/featuretags">opentype layout
        feature tags</a> that the [=original font=] has data for.</span>

Additionally:

   *  The response [=response/body=] should be encoded by one of the content encodings listed
        in the [[rfc9110#name-accept-encoding|Accept-Encoding]] header of the request. When possible
        the server should utilize one of the patch based encodings from [[#patch-encodings]]. Non-patch
        based encodings should only be used where the server is unable to recreate the client's state
        in order to generate a patch against it.

Note: if a patch subset service is composed of more than one server task and some subset of those
tasks are using a subsetter version which produces different binary results than the rest, there is
a risk that consecutive extend requests may result in unnecessary replacement responses. For example if
consecutive requests alternate between server backends with different subsetters, then each response
will be a replacement as the server tasks will be unable to recreate the previously generated
subset. This scenario might occur during software updates to the server tasks. To combat this
it's recommended that sticky load balancing is used which aims to send consecutive requests from the
same client to the same server task.

Possible error responses:


*  <span class="conform server" id="conform-reject-malformed-request">
     If the request is malformed the server must instead respond with http [=response/status=] code 400
     to indicate an error.</span>

*  If the requested font is not recognized by the server it should respond with http
    [=response/status=] code 404 to indicate a not found error.

### Range Request Support ### {#range-request-support}

A patch subset support server must also support incremental transfer via [[#range-request-incxfer]].
To support range request incremental tranfser the patch subset server must support HTTP range requests
([[RFC9110#range.requests]]) against the font files it provides via patch subset.


Computing Checksums {#computing-checksums}
------------------------------------------

64 bit checksums of byte strings are computed using the
[[!fast-hash]] algorithm. A python like pseudo
code version of the algorithm is presented below:

```
# Constant values come fast hash: https://github.com/ztanml/fast-hash
SEED = 0x11743e80f437ffe6
M = 0x880355f21e6d1965

mix(value):
  value = value ^ (value >> 23)
  value = value * 0x2127599bf4325c37
  value = value ^ (value >> 47)
  return value

fast_hash(byte[] data):
  # When casting byte arrays into unsigned 64 bit integers the bytes are in little
  # endian order. That is the smallest index is the least significant byte.
  uint64 hash = SEED ^ (length(data) * M)
  for (i = 0; i <= length(data) - 8; i += 8)
    hash = (hash ^ mix((uint64) data[i:i+8])) * M

  remaining = length(data) % 8
  if not remaining:
    return mix(hash)

  uint64 last_value = (uint64) concat(data[length(data) - remaining:],
                                      [0] * (8 - remaining))
  return mix((hash ^ mix(last_value)) * M)
```

To ensure checksums are consistent across all platforms, all integers during the computation are
in little endian order.

Note: a C implementation of fast hash can be found here: [[!fast-hash]]

<div class=example>

<table>
  <tr><th>Bytes</th><th>Checksum value</th></tr>
  <tr>
    <td>0f 7b 5a e5</td>
    <td>0xe5e0d1dc89eaa189</td>
  </tr>
  <tr>
  <td>1d f4 02 5e d3 b8 43 21 3b ae de</td>
  <td>0xb31e9c70768205fb</td>
  </tr>
</table>

</div>

Codepoint Reordering {#codepoint-reordering}
--------------------------------------------

A codepoint reordering for a font defines a function which maps unicode codepoint values from the
font to a continuous space of [0, number of codepoints in the font). This transformation is intended
to reduce the cost of representing codepoint sets.

<span class="conform server " id="conform-remap-all">A codepoint ordering is encoded into a
[=IntegerList=]. The list must contain all unicode codepoints that are supported by the
font.</span> The index of a particular unicode codepoint in the list is the new value for that
codepoint.

A server is free to choose any codepoint ordering, but should try to pick one that will minimize the
size of encoded codepoint sets for that font.

### Codepoint Reordering Checksum ### {#reordering-checksum}

A checksum of a codepoint reordering can be computed as follows:

```
SEED = 0x11743e80f437ffe6
M = 0x880355f21e6d1965

mix(value):
  value = value ^ (value >> 23)
  value = value * 0x2127599bf4325c37
  value = value ^ (value >> 47)
  return value

fast_hash_ordering(uint64[] ordering):
  uint64 hash = SEED ^ (length(ordering) * 8 * M)
  for i in ordering:
    hash = (hash ^ mix(ordering[i])) * M

  return mix(hash)
```

To ensure checksums are consistent across all platforms, all integers during the computation are
in little endian order.

<div class=example>

<table>
  <tr><th>Codepoint Ordering</th><th>Checksum value</th></tr>
  <tr>
    <td>[106, 97, 105, 120, 100]</td>
    <td>0x6986dc19f4e621e</td>
  </tr>
</table>

</div>

Patch Encodings {#patch-encodings}
----------------------------------

The following [[rfc9110#name-content-encoding|content encodings]] can be used to encode a target
file as a patch against a source file:

<table>
  <tr>
    <th>Name</th><th>Description</th><th>Notes</th>
  </tr>
  <tr>
    <td>brdiff</td>
    <td>Brotli Shared Dictionary</td>
    <td>
      The target file is encoded with [[!RFC7932|brotli compression]] using the
      source file as a [[!Shared-Brotli|shared LZ77 dictionary]]. If the source file is empty then
      the target file is just compressed using [[!RFC7932|brotli compression]] with no shared
      dictionary.
      
      <span class="conform server client" id="conform-brdiff">
      All client and server implementations must support this format.
      </span>
   </td>
  </tr>
  <tr>
    <td>vcdiff</td>
    <td>VCDIFF Patch</td>
    <td>
      Uses VCDIFF format [[!RFC3284]] to produce the patch.
    </td>
  </tr>
</table>


Binned Incremental Font Transfer (IFTB) {#binned-incxfer}
===========================================================

Introduction to IFTB {#iftb-intro}
----------------------------------

<em>This section is not normative.</em>

IFTB is a set of file formats that allow an input font to be reprocessed into an <em>initial file</em>
and a set of corresponding <em>chunk files</em>, the later containing glyph outline data for a set of
glyphs indexed by GID.

There are two specified input file formats. The first is an uncompressed variant of the OpenType "sfnt"
format but with the version tag "IFTB" and an extra "IFTB table. The second is the WOFF2 encoding of
that format with all tables in the same order.

There are also two chunk file formats. The first is the uncompressed chunk table structure described
below. The second has the same content but with all data following the header encoded with
[[!RFC7932|brotli compression]]. Each chunk can be stored in its own file.

The final format consists of all compressed chunks stored in order by chunk index in a single "range
file". Chunks can optionally be retrieved from this file using HTTP range requests.

(In the discussion below the term "chunk" and "bin" will be used somewhat interchangeably, but formally
the "bins" are what codepoints and then GIDs are assigned to while the "chunks" are the actual byte
strings containing glyph data.)

Font organization {#font-organization}
--------------------------------------

### Glyph Content ### {#iftb-glyph-content}

The term <dfn>outline table</dfn> is used to describe these three tables, which carry different types
of glyph outlines:

-   The <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cff"><code>CFF</code></a>
    table
-   The <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cff2"><code>CFF2</code></a>
    table
-   The <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/glyf"><code>glyf</code></a>
    table and its associated
    <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/loca"><code>loca</code></a>table
-   The <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cff2"><code>gvar</code></a>
    table

An IFTB font must have either one CFF table, one CFF2 table, or one pair of glyf/loca tables.  A
variable glyf-table-based font will also have a gvar table.

### CFF and CFF2 Requirements and Recommendations ### {#iftb-cff-requirements}

When an IFTB-encoded font includes a CFF or CFF2 table:

1.   The CharStrings Index MUST be the last element of the table (followed by 0 padding to a four-byte
     word boundary).
2.   The CharStrings Index offset size MUST be 4.
3.   The offset of the CharStrings index from the start of the CFF table MUST be stored accurately in
     the relevant field of the IFTB table header.
4.   All GIDs in the binned set must be represented in the index from the start, with trailing
     zero-offset-change entries if needed.

An "empty" glyph in a CFF table MUST be encoded as a single "endchar" operator. An empty glyph in a
CFF2 table MUST be encoded as a zero-length string.

CFF or CFF2 subroutinization is compatible with the IFTB format. However, <em>naive</em>
subroutinization will tend to reduce chunk size while increasing the size of the initial file. Also,
WOFF2 has often been shown to compress a non-subroutinized font more effectively than its subroutinized
equivalent (at the cost of a significantly larger uncompressed file).  Therefore, it is recommended
that subroutinzation either be avoided, used moderately, or customized to the specific needs of IFTB
incremental transfer.

### glyf/loca Requirements and Recommendations ### {#iftb-glyf-requirements}

When an IFTB-encoded font includes glyf and loca tables:

1.  The offset type of the loca table, specified in a field in the head table, MUST be the "Long"
     version.
2.  All GIDs in the binned set must be represented in the loca table from the start, with trailing
     zero-offset-change entries if needed.
3.  The tables must not be internally compressed.

### gvar Requirements and Recommendations ### {#iftb-gvar-requirements}

When an IFTB-encoded font includes a gvar table:

1.  The glyphVariationData set MUST be the last element in the table (followed by 0 padding to a
     four-byte word boundary.
2.  The offset type MUST be Offset32.
3.  All GIDs in the binned set MUST be represented in the array from the start, with trailing 
     zero-offset-change entries if needed.

Note that the offset array itself is not required to be stored at any particular location in the table.

### Table Ordering ### {#iftb-table-ordering}

No two tables in an IFTB font should share a tag name.

In a CFF or CFF2 based IFTB font that table must be last. In a glyf/loca based IFTB font the last
tables must be glyf and loca in that order (loca following glyf is a requirement inherited from WOFF2).
If the font contains a gvar table it must come immediately before the glyf table.

There are no other ordering requirements. However, it is highly recommended that the IFTB and cmap
tables come early in the list and before any other lengthy table.

IFTB Font Formats {#iftb-font-formats}
--------------------------------------

The specification allows for two initial font formats:

1.   The uncompressed format is a slight variant of the OpenType "sfnt" format, but with a version tag 
     of `IFTB` instead of `0x00010000` or `OTTO`.
2.   The compressed format is a WOFF2 encoding of the uncompressed format with all tables in the same
     order.  The sfnt "flavor" in the WOFF2 header must accordingly also be `IFTB`. 

It is expected that the client will almost always download a WOFF2-encoded file, which it will then
unpack into the uncompressed format and modify as needed.

Before loading a copy of the uncompressed font into the browser, or making it available to some other
renderer, the version should be changed to `0x00010000` if the font has a glyf table or `OTTO` if it
has a CFF or CFF2 table.  However, if the file is cached it should be stored with the `IFTB` version.
(The differing version is to help prevent an IFTB-encoded font from being used accidentally as a 
standard font, which will generally result in blank spaces where some glyphs should be rendered.)

IFTB Table {#iftb-table}
------------------------

The IFTB table contains information needed to determine what chunks are needed for a given font subset
description, and then to retrieve and integrate those chunks. It is similar in layout to analogous
OpenType tables, and is accordingly described in terms of the [OpenType Specification Data
Types](https://learn.microsoft.com/en-us/typography/opentype/spec/otff#data-types). As with OpenType
all fields use Big Endian byte orderng.

### IFTB Table Header ### {#iftb-table-header}

```
uint16     majorVersion   - set to 1
uint16     minorVersion   - set to 0
uint32     reserved       - not used, set to 0
uint32     id[4]          - ID uniquely identifying this IFTB font
uint16     flags          - not yet used
uint32     chunkCount     - number of bins in this IFTB font
uint32     glyphCount     - must match field in maxp table
Offset32   CFFCharStringsOffset  - 0 if glyf-based
Offset32   gidMapOffset
Offset32   chunkOffsetListOffset
Offset32   featureMapOffset
```

### IFTB Chunk Set ### {#iftb-chunk-set}

The header is followed by the chunk set:

```
uint8     chunkSet[(chunkCount + 7) / 8]
```

The chunk set is effectively a bit array indicating whether the corresponding chunk is present.  The
bits for chunks 0 through 7 are in chunkSet[0], those for 8 through 15 are in chunkSet[1], and so on.
Within a byte the lowest chunk index is represented by the 1s bit, then the 2s, then the 4s, and so on.

Because chunk 0 must always be included in the initial font file, its bit is always set.  Other bits
may also be set at the start if other chunks are <a href="#iftb-preloading">preloaded</a>.  This array
must be updated as chunks are integrated into the font, and is the only part of the IFTB table that
changes after the initial encoding into IFTB format.

### IFTB Table Strings ### {#iftb-table-strings}

The chunkMap is directly followed by two strings in this format:

```
uint8      stringLength
int8       stringContent[stringLength]
uint8      terminator    - set to 0
```

The first string is the chunkFilesURI, which is a template for forming relative the URI for a chunk
file.  The string must contain substrings of "$1", "$2", "$3", "$4" and/or "$5", which must be replaced
with the corresponding hexidecimal digits of the chunk index ("$1" being the ones digit, "$2" being the
sixteens digit, and so on) to get the relative URI of the chunk. (This can then be combined with the
URL of the initial IFTB font file to produce the absolute URL of the chunk.)

The second string is the chunkRangeFileURI, which is also relative. This can be combined with the URL
of the initial IFTB font file to produce the absolute URL of the range file. The range file contains
all compressed chunk files in order, at offsets recorded in the chunkOffsetList.

### IFTB gidMap ### {#iftb-gidmap}

The gidMap maps each glyph, via GID, to a chunk index. 

```
uint16     firstMappedGID
chunkIdx   chunkIndex[chunkCount - firstMappedGid + 1]
```

The `chunkIdx` data type is `uint8` when `chunkCount < 256` and `uint16` otherwise.

When a GID is less than `firstMappedGID` it is implicitly mapped to chunk 0. For all others the mapping
is stored as chunkIndex[GID - firstMappedGID].

Note that the mapping for a GID corresponding to one or more Unicode codepoints has a different meaning
than a mapping for a GID without one. In normal operation a glyph of the latter type will be loaded
because it is included in a chunk corresponding to a different glyph with an associated codepoint. The
mapping of other GIDs is included for unusual cases in which a client needs to load a particular glyph
for its own reasons. (For example, a CFF font may have a CID mapping not completely replicated in the
`cmap` table.)

### IFTB chunkOffsetList ### {#iftb-chunkoffsetlist}

The chunkOffsetList is an array of chunk offsets indicating the start of the chunk in the chunk range
file:

```
Offset32    chunkOffset[chunkCount]
```

The offset of chunk *i* is stored at `chunkOffset[i-1]` (because chunk 0 is always part of the
initially loaded file), with chunkOffset[chunkCount] indicating the length of the last chunk.

These offsets are normally only used when making range requests out of the chunk range file but can
also be used to lookup the lengths of compressed chunks in advance if needed.

### IFTB featureMap subtable ### {#iftb-table-featuremap}

The featureMap records what feature-specific chunks, if any, correspond to a codepoint-mapped chunk:

```
uint16         featureCount
FeatureRecord  featureRecord[featureCount]
ChunkMapRecord chunkMapRecord[varies]
```

A `FeatureRecord`` consists of these fields:

```
uint32         featureTag
chunkIdx       firstIndex
chunkIdx       chunkMapCount
```

As in the gidMap the `chunkIdx` data type is a `uint8` when `chunkCount <= 256` and a `uint16`
otherwise. 

The `featureRecord` array must be sorted by `featureTag`, with any feature tag occurring at most once.
Only layout features that have their own chunks should be have a `FeatureRecord`.  `firstIndex` is the
chunk index of the first chunk specific to this feature. The number of feature-specific chunks will
then be `chunkRecordCount`, which must be at least 1. The chunk correspondence is encoded in
`ChunkMapRecords`:

```
chunkIdx      firstChunk
chunkIdx      lastChunk
```

The `chunkMapRecord` array contains as many entries as the sum of `chunkMapCount` fields in the
`featureRecord` array, with chunkMapRecord[0] corresponding to the first chunk of featureRecord[0],
chunkMapRecord[featureRecord[0].chunkMapCount] corresponding to the first chunk of featureRecord[1],
chunkMapRecord[featureRecord[0].chunkMapCount + chunkMapRecord[featureRecord[1].chunkMapCount]
corresponding to the first chunk of featureRecord[2], and so on.

`firstChunk` must be less than or equal to `lastChunk`. If `featureTag` is part of the set of layout
features in the font subset description, and any of firstChunk through lastChunk are required by the
set of codepoints in that description, then that feature-specfic chunk must also be loaded.

### Optional IFTB Table Values ### {#iftb-table-optional}

If a particular IFTB-encoded font does not include a range file the chunkRangeFileURI string must be
empty. The `chunkOffsetList` can either be included for reference or omitted by setting the
`chunkOffsetListOffset` field to 0.  If a particular font does not include separate chunk files the
`chunkFilesURI` field must be empty.

When an IFTB format font has no feature-specific chunks the `featureMapOffset` must be 0.

IFTB Chunk Formats {#iftb-chunk-formats}
----------------------------------------

### The Uncompressed Chunk Format (IFTC) ### {#iftc-format}

An uncompressed chunk string, which is normally produced by decoding a compressed chunk, has these
fields:

```
uint32        version     - must be "IFTC" tag
uint32        reserved    - must be 0
uint32        id[4]       - unique id -- must match same fields in IFTB table
uint32        chunkIndex  - (uint32) for potential future extensions
uint32        length      - the length of the (uncompressed) chunk string
uint32        glyphCount  - the number of glyphs encoded in the chunk
uint8         tableCount  - the number of tables the chunk has data for (must be 1 or 2)
uint16        GIDs[glyphCount]    - an array of GIDs included in the chunk
uint32        tables[tableCount]  - an array of tables (by tag) included in the chunk.
Offset32      offsets[glyphCount * tableCount] - an array of offsets of glyph data,
                                                 with the first glyphCount offsets corresponding
                                                 to table 1 and (if present) the second glyphCount
                                                 offsets corresponding to table 2. All offsets are
                                                 from the start of the table.
uint8         glyphData[varies]  - the actual glyph data picked out by the offsets.
```

`tableCount` will be 2 only when there is both a `glyf` and a `gvar` table.  Otherwise `tableCount`
will be 1 and the table will be `CFF `, `CFF2`, or `glyf`.

### The Compressed Chunk Format (IFTZ) ### {#iftz-format}

A compressed chunk string is the same as an uncompressed chunk string except:

1.  The `version` is `IFTZ`.
2.  All data after the `length` field is [[!RFC7932|brotli compressed]]

The compressed chunk contains no indication of its (compressed) length, but that length is encoded
in the `chunkOffsetList` of the IFTB table.

Browser Behaviors {#iftb-browser-behaviors}
-------------------------------------------

### First Request ### {#iftb-browser-behaviors-first-request}

1.  The browser loads a font file and identifies it as an IFTB font by its "sfnt" header version (in
     the uncompressed case) or by its WOFF2 "flavor" (in the compressed case).  These are the first
     and second 4-byte words in the files respectively.
2.  In the compressed case, decode the WOFF2 into its corresponding OTF.  Optionally isolate the IFTB
     and cmap tables early in the stream to proceed before the remaining font content downloads.
3.  The browser determines the initial font subset description corresponding to the content it needs to
     render using the font.  (IFTB does not subset variable axes, so this is just the sets of
     codepoints and layout features.)
4.  The browser maps each codepoint in the font subset description to a GID using the cmap table. It
     then maps that GID to a chunk index using GIDMap of the IFTB table. That index is added to a
     "chunk set" (which could be a bitmap or std::vector<bool> indexed by chunk index.
5.  The browser then look up each layout feature in the font subset description in the IFTB table
     featureTable. That table maps the initial GID-mapped chunks to higher-indexed feature-specific
     chunks. If any chunk in the set maps to a feature-specific-chunk the latter is added to the set.
6.  The browser subtracts the list of already-included chunks recorded in the IFTB ChunkMap from the
     chunk set.  If no chunks remain, the process skips to step XXX.
7.  At this point there are two options for retrieving chunk contents:

     Load each needed chunk using individual files:
     1.  Calculate the hex string for the chunk index
     2.  Get the chunkFilesURI string from the IFTB table and substitute "$1", "$2", ... with
          the corresponding hex digit.
     3.  Combine the relative URI with the URL of the original font to get the URL for the chunk.
     4.  Request that file via HTTP.

     Load each needed chunk from the range file:
     1.  Get the chunkRangeFileURI from the string IFTB table.
     2.  Combine that URI with the URL of the original font to get the URL for the range file.
     3.  Get the byte range for each chunk from the chunkOffsetTable in the IFTB table.
     4.  Form a HTTP range request for those byte ranges using the combined URL.
8.  Decompress each retrieved chunk content.
9.  Merge the glyph contents in all of the chunks into the corresponding tables, reallocating the
     memory for the font if necessary. (All of the relevant tables use an offset array and concatenated
    glyph data convention.)
10. Update the IFTB table to record the chunks added (the table will not change in length).
11. Update the "sfnt" headers for the correct offsets, sizes, and (if needed by the client) checksums.
     (Only the trailing CFF, CFF2, glyf, loca and or gvar tables will change in size or location.) Also
     update the checksumAdjustment in the head table (if needed by the client).
12. If caching, store the file at this point.
13. Update the SFNT version to 0x00010000 (for a glyf table) or "OTTO" (for a CFF or CFF2 table) and
     also the head table checksumAdjustment again (if needed by the client).
14. Render the text with the updated font.

### Subsequent Requests ### {#iftb-browser-behaviors-subsequent-requests}

Subsequent requests proceed like the initial request starting at step 3.

IFTB Encoding {#iftb-encoding}
------------------------------

An input font is encoded in the IFTB format using an encoder as a separate, initial step.  If any other
subsetting (such as removing or reducing variable axes, or removing glyphs that are not needed) is
desired the input font should be subset using another program prior to IFTB encoding.

With the IFTB format only glyph data is transferred incrementally. The format also "retains" GIDS 
the input font's GIDs, and therefore most tables can be copied from the source font.  However, an
encoder can deserialize and reserialize tables if it desires.

The details of the encoding process may differ by encoder and are beyond the scope of this document.
However, all mappings of codepoints (though GIDs) to bins and bins to feature-specific bins must meet
this closure requirement:

* The set of glyphs contained in the chunks loaded through the GID and feature maps must be a superset
    of those in the GID closure of the font subset description.

The encoder has a number of options in dealing with joint dependencies on individual glyphs:

1.  If a glyph is needed in more than one initial "trial" bin, those bins can be combined.
2.  Alternatively, the glyph can be included in both bins, or more than two bins.  (The glyph will only
     be mapped to one chunk in the `gidMap`, and special care must be taken about which chunk it maps
     to if it has an associated codepoint. However, the encoder is free to include it in other bins
     as long as the closure requirement is met.)
3.  If a glyph is needed in more than a few trial bins, or is otherwise complicating the binning
     process, it can be moved to bin 0 where it will always be included in the initially loaded file.

Glyph Bin Locality {#iftb-bin-locality}
---------------------------------------

A typical IFTB-encoded font will have between eighty and five-hundred bins. Higher numbers of bins may
result in unacceptable overhead and diminishing returns. However, if glyphs were randomly distributed
among bins most of them might be needed to render a typical document.

Therefore it is vital to efficiency to distribute glyphs among bins so that fewer chunks must be 
loaded. The most basic strategy will be assigning glyphs to bins by frequency of use, so that more
frequently needed glyphs will be concentrated together in bins. However, *just* ordering by frequency
is often a mistake, because there are many more documents that need, for example, glyphs for writing
Korean or glyphs for writing Greek than there are documents that need both.

Therefore, it is best to start with an idea of how the encoded font will typically be used. One primary
use-case for font augmentation is for use with CJK-oriented fonts. A given font might "specialize" in
a given script or language subset (e.g. traditional Chinese vs Hong Kong Chinese) whereas other fonts
might be general. If a font will be used with one language or dialect it can be encoded with frequency
data for that specific application.

If the font will be used with multiple languages and/or dialects, however, one approach is to obtain
frequency data for each and then establish a high-frequency-glyph "cut-off" for each.  You can then 
determine the intersecting sets of high frequency glyphs and ensure these wind up in their own chunks.
For example, if you are encoding for Japanese, Korean, and traditional Chinese, you may choose to
consider the top 3000, 1800, and 2300 glyphs of each respectively to be high-frequency. You can then
form a group of high frequency glyphs in all three sets, a group in both Japanese and Korean, a group
in both Japanese and Chinese, a group in both Korean and Chinese, and then the remaining glyphs for
each individual language, and encode each group separately (in combined order of frequency, if
available, and in order by frequency in one language otherwise) in their own set of chunks. That way
rendering a Chinese document can load high-frequency Chinese glyphs while avoiding Korean glyphs and
vice-versa. 

The assignment of high frequency glyphs to bins will have the most effect on performance.
Low-frequency glyphs are least important, but there is still some locality to be exploited. For
example, there is a set of Unicode codepoints used for rendering boxes. These are rarely used, but need
one is predictive of needing the others.  As such glyphs tend to be grouped by codepoint value anyway,
it is often sufficient to order low-frequency glyphs by codepoint when assigning them to bins.

In between are the medium-frequency codepoints. When those codepoints are specific to a language or
script, they can just be grouped and ordered by frequency in that language or script.  (This is true,
broadly speaking, of many Hangul glyphs for writing Korean.) When multiple languages share 
medium-frequency codepoints things become trickier. One strategy is to pick one language or script and
order the medium-frequency codepoints according to its frequency, either letting the others suffer in
performance somewhat or, if desired, granting one or more their own IFTB encodings. 

Preloadng {#iftb-preloading}

Requesting, waiting for, and integrating chunks into an IFTB-encoded font all involve some overhead
compared with loading an initial file that already includes that data. (The size of glyph data in a
compressed chunk will typically be a bit larger than its size in a WOFF2-encoded initital file, as
Brotli compression is very good at recognizing and making use of common content, and chunks tend to
have relatively less content.)  Therefore it is best to include those glyphs that are most frequently
used in the initial file.

If a font has a single purpose, one may choose to include the high frequency codepoints in chunk 0.
When it has multiple purposes one has the option of encoding for each purpose separately, with the
high frequency codepoints for a given purpose in chunk 0 of its respective encoding.  However, that
approach has several disadvantages related to file sizes and caching: The data for the entire font is
repeated in each encoding. The number of files used is multiplied. And perhaps most importantly,
requests for chunks are spread over the different versions, increasing the probability of a CDN cache
miss for a given encoding. (So, for example, the caching chunks for a less common purpose won't benefit
from the more frequent requests for chunks, and therefore the higher chance of a cache hit, for a more
common purpose.)

Instead of encoding separate copies, it will often be better to encode the font for mulitple uses, as
described in the last section, and then to *pre-load* chunks for a given use into an initial copy of
the font. Preloading is doing on the server-side something close to what the client would do after
first loading the font: The chunks are "loaded", their contents are integrated into the relevant
tables, and the IFTB chunk set is updated. After this, the file is re-encoded in WOFF2 format.  Because
the URIs for chunks and for the range file are relative, as long as the preloaded copy of the initial
font is served in the same directory as the original copy, subsequent chunks will be loaded in the same
way.

<h2 class=no-num id=priv>Privacy Considerations</h2>

<h3  id="content-inference-from-character-set">Content inference from character set</h3>

Patch-subset exposes, to the server hosting a Web font, the set of characters that the browser can
already render in a given Web font, and also the set of characters that it cannot render, but wants to
(for example, to render a new Web page). For details, see [[#extend-subset]].

The purpose of doing so is to allow the server to compute a binary patch to the existing font, adding
more characters. Thus, fonts are transferred incrementally, as needed, which <a
href="https://www.w3.org/TR/PFE-evaluation/#analysis-cjk">greatly reduces</a>> the bytes transferred
and the overall network cost..

For some languages, which use a very large character set (Chinese and Japanese are examples) the vast
reduction in total bytes transferred means that Web fonts become usable, including on mobile networks,
for the first time.

However, for those languages, it is <em>possible</em> that individual requests might be analyzed by a
rogue font server to obtain intelligence about the type of content which is being read. It is unclear
how feasible this attack is, or the computational complexity required to exploit it, unless the
characters being requested are very unusual.

One mitigation, which was originally introduced for reasons of networking efficiency so is likely to be
implemented in practice, is to request additional, un-needed characters to dilute the ability to infer
what content the user is viewing. Requesting characters which are
<a href="https://www.w3.org/TR/PFE-evaluation/#codepredict">statistically likely to occur</a> may
<a href="https://docs.google.com/document/d/1u-05ztF9MqftHbMKB_KiqeUhZKiXNFE4TRSUWFAPXsk/edit">avoid a
subsequent request</a>.

(IFTP mandates HTTPS, so no in-the-middle attack is possible; the trust is between the client, and the
server hosting the fonts).

IFTB chunk requests pose no privacy risks as long as the bins are sufficiently coarse-grained.

<h3 id="checksum-and-possible-fingerprinting">Checksums and possible fingerprinting</h3>

In the patch subset method 64 bit checksums are generated and transferred between client and server.
These are used for error detection, are not persistent across browsing sessions, change frequently in
the course of a single browsing session, and thus should not pose a tracking risk.

Also, browsers typically cache resources keyed by the origin domain; thus the checksums and the set of
characters the client requires would only be available to that domain and the patch subset server.

<h3 id="per-origin">Per-origin restriction avoids fingerprinting</h3>

  As required by [[!css-fonts-4]],
  Web Fonts <a href="https://drafts.csswg.org/css-fonts-4/#web-fonts">must not be accessible
  in any other Document from the one which either is associated with the @font-face rule
  or owns the FontFaceSet.
  Other applications on the device must not be able to access Web Fonts.</a>
  This avoids information leaking across origins.

  Similarly, font palette values
  <a href="https://drafts.csswg.org/css-fonts-4/#font-palette-values">must only be available to the documents that reference it</a>.
  Using an author-defined color palette outside of the documents that reference it
  would constitute a security leak since the contents of one page
  would be able to affect other pages,
  something an attacker could use as an attack vector.

<h2 class=no-num id=sec>Security Considerations</h2>

No Security issues have been raised against this document

<h2 id="feature-tag-list">
Appendix A: Default Feature Tags and Encoding IDs</h2>

<pre class=include>
<!-- Edit feature-registry.csv to update this table. -->
path: feature-registry.html
</pre>
